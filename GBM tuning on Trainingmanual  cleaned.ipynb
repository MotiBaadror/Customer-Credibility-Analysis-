{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_key</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230032</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>1.6541</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>40369.000000</td>\n",
       "      <td>18414.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>6423.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>123875.0</td>\n",
       "      <td>216152.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.78</td>\n",
       "      <td>8987.180</td>\n",
       "      <td>3700.00</td>\n",
       "      <td>72.25</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>4532.0</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4532.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1.1667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08696</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.63899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230033</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>7532.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>18234.000000</td>\n",
       "      <td>13664.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>42613.0</td>\n",
       "      <td>216152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.25</td>\n",
       "      <td>953.060</td>\n",
       "      <td>953.06</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>30386.0</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>2829.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.63836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230034</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>0.4001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>2478.0</td>\n",
       "      <td>34097.436013</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>2977.5</td>\n",
       "      <td>4090.0</td>\n",
       "      <td>76109.0</td>\n",
       "      <td>216152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.69</td>\n",
       "      <td>3974.425</td>\n",
       "      <td>3700.00</td>\n",
       "      <td>40.44</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>4623.0</td>\n",
       "      <td>3772.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>25.0833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230035</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>26440.0</td>\n",
       "      <td>4955.0</td>\n",
       "      <td>20316.000000</td>\n",
       "      <td>37013.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84235.0</td>\n",
       "      <td>216152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.69</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3700.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>2525.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5992.0</td>\n",
       "      <td>2829.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>10.3333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15385</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.53241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230036</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>5494.0</td>\n",
       "      <td>5494.0</td>\n",
       "      <td>7987.000000</td>\n",
       "      <td>4696.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>27815.0</td>\n",
       "      <td>123875.0</td>\n",
       "      <td>524848.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.51</td>\n",
       "      <td>796.670</td>\n",
       "      <td>3700.00</td>\n",
       "      <td>28.72</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>2707.0</td>\n",
       "      <td>2829.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_key       0       1      2    3    4       5        6       7  \\\n",
       "0           230032  1696.0  1.6541  0.000  0.0  0.0     0.0   6015.0   322.0   \n",
       "1           230033  1846.0  0.8095  0.000  0.0  0.0   102.0   7532.0  3171.0   \n",
       "2           230034  1745.0  0.4001  0.000  0.0  0.0   297.0   2536.0  2478.0   \n",
       "3           230035  1739.0  0.2193  0.000  0.0  0.0  1982.0  26440.0  4955.0   \n",
       "4           230036  1787.0  0.0118  0.225  0.0  0.0  5451.0   5494.0  5494.0   \n",
       "\n",
       "              8        9      10      11       12        13        14   15  \\\n",
       "0  40369.000000  18414.0  1780.0  6423.0   3067.0  123875.0  216152.0  1.0   \n",
       "1  18234.000000  13664.0  1780.0   765.0   1931.0   42613.0  216152.0  0.0   \n",
       "2  34097.436013   2536.0  1780.0  2977.5   4090.0   76109.0  216152.0  0.0   \n",
       "3  20316.000000  37013.0  1780.0     0.0      0.0   84235.0  216152.0  0.0   \n",
       "4   7987.000000   4696.0  1780.0  2257.0  27815.0  123875.0  524848.0  0.0   \n",
       "\n",
       "    16   17   18   19     20        21       22     23      24      25  \\\n",
       "0  1.0  1.0  3.0  3.0  94.78  8987.180  3700.00  72.25  1462.0  4532.0   \n",
       "1  0.0  0.0  0.0  0.0  74.25   953.060   953.06   4.80  1028.0  2099.0   \n",
       "2  0.0  0.0  0.0  0.0  59.69  3974.425  3700.00  40.44  1472.0  2738.0   \n",
       "3  0.0  0.0  0.0  0.0  59.69     0.000  3700.00   0.00  1308.0  2525.0   \n",
       "4  0.0  0.0  0.0  0.0  20.51   796.670  3700.00  28.72   801.0  2281.0   \n",
       "\n",
       "       26       27      28      29     30       31   32    33   34   35  \\\n",
       "0  2890.0     61.0  4532.0  1095.0  625.0   1.1667  8.0  10.0  4.0  1.0   \n",
       "1  2099.0  30386.0  2281.0  2829.0  169.0   0.4167  8.0   0.0  2.0  0.0   \n",
       "2  2555.0    669.0  4623.0  3772.0  300.0  25.0833  1.0   3.0  1.0  0.0   \n",
       "3   791.0     91.0  5992.0  2829.0  215.0  10.3333  3.0   3.0  2.0  0.0   \n",
       "4  2281.0    487.0  2707.0  2829.0  158.0   0.9167  2.0   3.0  2.0  0.0   \n",
       "\n",
       "        36    37       38   39   40       41   42   43  \n",
       "0  0.08696  10.0  0.63899  0.0  1.0  156.327  0.0  0.0  \n",
       "1  0.00000  13.0  0.63836  1.0  0.0   99.129  0.0  1.0  \n",
       "2  0.00000   1.0  1.00000  0.0  0.0   29.290  0.0  1.0  \n",
       "3  0.15385   3.0  0.53241  1.0  0.0   96.272  0.0  0.0  \n",
       "4  0.00000   1.0  0.92665  1.0  0.0  115.019  0.0  0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Training_manual_cleaned.csv')\n",
    "target = '43'\n",
    "IDcol = 'application_key'\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BaadRoR\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\BaadRoR\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain[target], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print(\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "# gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "# modelfit(gbm0, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(0,1,39,40,36,6,37,5,41,23,9,24,4,18,12,42,14,25,31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best  n_estimators 80 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=50, min_samples_split=500,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=10, subsample=0.8, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': [80, 90, 100, 110, 120, 130, 140, 150, 160, 170]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "param_test1 = {\"n_estimators\":[80,90,100,110,120,130,140,150,160,170]}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.2, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83647, std: 0.00632, params: {'n_estimators': 80},\n",
       "  mean: 0.83610, std: 0.00634, params: {'n_estimators': 90},\n",
       "  mean: 0.83554, std: 0.00621, params: {'n_estimators': 100},\n",
       "  mean: 0.83517, std: 0.00640, params: {'n_estimators': 110},\n",
       "  mean: 0.83474, std: 0.00636, params: {'n_estimators': 120},\n",
       "  mean: 0.83441, std: 0.00655, params: {'n_estimators': 130},\n",
       "  mean: 0.83379, std: 0.00667, params: {'n_estimators': 140},\n",
       "  mean: 0.83320, std: 0.00688, params: {'n_estimators': 150},\n",
       "  mean: 0.83292, std: 0.00659, params: {'n_estimators': 160},\n",
       "  mean: 0.83265, std: 0.00664, params: {'n_estimators': 170}],\n",
       " {'n_estimators': 80},\n",
       " 0.836467092357205)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_depth 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83766, std: 0.00624, params: {'max_depth': 5, 'min_samples_split': 200},\n",
       "  mean: 0.83789, std: 0.00620, params: {'max_depth': 5, 'min_samples_split': 400},\n",
       "  mean: 0.83844, std: 0.00641, params: {'max_depth': 5, 'min_samples_split': 600},\n",
       "  mean: 0.83831, std: 0.00599, params: {'max_depth': 5, 'min_samples_split': 800},\n",
       "  mean: 0.83819, std: 0.00630, params: {'max_depth': 5, 'min_samples_split': 1000},\n",
       "  mean: 0.83817, std: 0.00658, params: {'max_depth': 5, 'min_samples_split': 1200},\n",
       "  mean: 0.83786, std: 0.00612, params: {'max_depth': 5, 'min_samples_split': 1400},\n",
       "  mean: 0.83762, std: 0.00597, params: {'max_depth': 5, 'min_samples_split': 1600},\n",
       "  mean: 0.83772, std: 0.00612, params: {'max_depth': 7, 'min_samples_split': 200},\n",
       "  mean: 0.83868, std: 0.00656, params: {'max_depth': 7, 'min_samples_split': 400},\n",
       "  mean: 0.83828, std: 0.00665, params: {'max_depth': 7, 'min_samples_split': 600},\n",
       "  mean: 0.83879, std: 0.00648, params: {'max_depth': 7, 'min_samples_split': 800},\n",
       "  mean: 0.83889, std: 0.00653, params: {'max_depth': 7, 'min_samples_split': 1000},\n",
       "  mean: 0.83867, std: 0.00596, params: {'max_depth': 7, 'min_samples_split': 1200},\n",
       "  mean: 0.83890, std: 0.00630, params: {'max_depth': 7, 'min_samples_split': 1400},\n",
       "  mean: 0.83888, std: 0.00615, params: {'max_depth': 7, 'min_samples_split': 1600},\n",
       "  mean: 0.83578, std: 0.00611, params: {'max_depth': 9, 'min_samples_split': 200},\n",
       "  mean: 0.83643, std: 0.00588, params: {'max_depth': 9, 'min_samples_split': 400},\n",
       "  mean: 0.83753, std: 0.00555, params: {'max_depth': 9, 'min_samples_split': 600},\n",
       "  mean: 0.83708, std: 0.00631, params: {'max_depth': 9, 'min_samples_split': 800},\n",
       "  mean: 0.83764, std: 0.00595, params: {'max_depth': 9, 'min_samples_split': 1000},\n",
       "  mean: 0.83825, std: 0.00612, params: {'max_depth': 9, 'min_samples_split': 1200},\n",
       "  mean: 0.83880, std: 0.00589, params: {'max_depth': 9, 'min_samples_split': 1400},\n",
       "  mean: 0.83866, std: 0.00593, params: {'max_depth': 9, 'min_samples_split': 1600},\n",
       "  mean: 0.83426, std: 0.00589, params: {'max_depth': 11, 'min_samples_split': 200},\n",
       "  mean: 0.83624, std: 0.00638, params: {'max_depth': 11, 'min_samples_split': 400},\n",
       "  mean: 0.83650, std: 0.00618, params: {'max_depth': 11, 'min_samples_split': 600},\n",
       "  mean: 0.83794, std: 0.00559, params: {'max_depth': 11, 'min_samples_split': 800},\n",
       "  mean: 0.83763, std: 0.00600, params: {'max_depth': 11, 'min_samples_split': 1000},\n",
       "  mean: 0.83789, std: 0.00617, params: {'max_depth': 11, 'min_samples_split': 1200},\n",
       "  mean: 0.83808, std: 0.00643, params: {'max_depth': 11, 'min_samples_split': 1400},\n",
       "  mean: 0.83842, std: 0.00617, params: {'max_depth': 11, 'min_samples_split': 1600},\n",
       "  mean: 0.83261, std: 0.00613, params: {'max_depth': 13, 'min_samples_split': 200},\n",
       "  mean: 0.83500, std: 0.00585, params: {'max_depth': 13, 'min_samples_split': 400},\n",
       "  mean: 0.83539, std: 0.00583, params: {'max_depth': 13, 'min_samples_split': 600},\n",
       "  mean: 0.83649, std: 0.00604, params: {'max_depth': 13, 'min_samples_split': 800},\n",
       "  mean: 0.83616, std: 0.00583, params: {'max_depth': 13, 'min_samples_split': 1000},\n",
       "  mean: 0.83701, std: 0.00606, params: {'max_depth': 13, 'min_samples_split': 1200},\n",
       "  mean: 0.83721, std: 0.00614, params: {'max_depth': 13, 'min_samples_split': 1400},\n",
       "  mean: 0.83795, std: 0.00597, params: {'max_depth': 13, 'min_samples_split': 1600},\n",
       "  mean: 0.82873, std: 0.00569, params: {'max_depth': 15, 'min_samples_split': 200},\n",
       "  mean: 0.83228, std: 0.00646, params: {'max_depth': 15, 'min_samples_split': 400},\n",
       "  mean: 0.83432, std: 0.00572, params: {'max_depth': 15, 'min_samples_split': 600},\n",
       "  mean: 0.83510, std: 0.00586, params: {'max_depth': 15, 'min_samples_split': 800},\n",
       "  mean: 0.83602, std: 0.00636, params: {'max_depth': 15, 'min_samples_split': 1000},\n",
       "  mean: 0.83695, std: 0.00624, params: {'max_depth': 15, 'min_samples_split': 1200},\n",
       "  mean: 0.83734, std: 0.00570, params: {'max_depth': 15, 'min_samples_split': 1400},\n",
       "  mean: 0.83757, std: 0.00633, params: {'max_depth': 15, 'min_samples_split': 1600},\n",
       "  mean: 0.82858, std: 0.00618, params: {'max_depth': 17, 'min_samples_split': 200},\n",
       "  mean: 0.83123, std: 0.00555, params: {'max_depth': 17, 'min_samples_split': 400},\n",
       "  mean: 0.83453, std: 0.00701, params: {'max_depth': 17, 'min_samples_split': 600},\n",
       "  mean: 0.83506, std: 0.00645, params: {'max_depth': 17, 'min_samples_split': 800},\n",
       "  mean: 0.83567, std: 0.00644, params: {'max_depth': 17, 'min_samples_split': 1000},\n",
       "  mean: 0.83671, std: 0.00692, params: {'max_depth': 17, 'min_samples_split': 1200},\n",
       "  mean: 0.83724, std: 0.00631, params: {'max_depth': 17, 'min_samples_split': 1400},\n",
       "  mean: 0.83690, std: 0.00595, params: {'max_depth': 17, 'min_samples_split': 1600},\n",
       "  mean: 0.82746, std: 0.00549, params: {'max_depth': 19, 'min_samples_split': 200},\n",
       "  mean: 0.83114, std: 0.00668, params: {'max_depth': 19, 'min_samples_split': 400},\n",
       "  mean: 0.83164, std: 0.00575, params: {'max_depth': 19, 'min_samples_split': 600},\n",
       "  mean: 0.83417, std: 0.00541, params: {'max_depth': 19, 'min_samples_split': 800},\n",
       "  mean: 0.83556, std: 0.00580, params: {'max_depth': 19, 'min_samples_split': 1000},\n",
       "  mean: 0.83634, std: 0.00608, params: {'max_depth': 19, 'min_samples_split': 1200},\n",
       "  mean: 0.83521, std: 0.00563, params: {'max_depth': 19, 'min_samples_split': 1400},\n",
       "  mean: 0.83692, std: 0.00557, params: {'max_depth': 19, 'min_samples_split': 1600}],\n",
       " {'max_depth': 7, 'min_samples_split': 1400},\n",
       " 0.8388978674150881)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':[5,7,9,11,13,15,17,19], 'min_samples_split':[200,400,600,800,1000,1200,1400,1600]}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.15, n_estimators=60, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min_samples_leaf': 30, 'min_samples_split': 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83947, std: 0.00664, params: {'min_samples_leaf': 30, 'min_samples_split': 1000},\n",
       "  mean: 0.83967, std: 0.00625, params: {'min_samples_leaf': 30, 'min_samples_split': 1200},\n",
       "  mean: 0.83933, std: 0.00604, params: {'min_samples_leaf': 30, 'min_samples_split': 1400},\n",
       "  mean: 0.83977, std: 0.00638, params: {'min_samples_leaf': 30, 'min_samples_split': 1600},\n",
       "  mean: 0.83985, std: 0.00627, params: {'min_samples_leaf': 30, 'min_samples_split': 1800},\n",
       "  mean: 0.84003, std: 0.00638, params: {'min_samples_leaf': 30, 'min_samples_split': 2000},\n",
       "  mean: 0.83965, std: 0.00645, params: {'min_samples_leaf': 30, 'min_samples_split': 2200},\n",
       "  mean: 0.83960, std: 0.00587, params: {'min_samples_leaf': 30, 'min_samples_split': 2400},\n",
       "  mean: 0.83926, std: 0.00616, params: {'min_samples_leaf': 40, 'min_samples_split': 1000},\n",
       "  mean: 0.83989, std: 0.00610, params: {'min_samples_leaf': 40, 'min_samples_split': 1200},\n",
       "  mean: 0.83951, std: 0.00623, params: {'min_samples_leaf': 40, 'min_samples_split': 1400},\n",
       "  mean: 0.83970, std: 0.00628, params: {'min_samples_leaf': 40, 'min_samples_split': 1600},\n",
       "  mean: 0.83955, std: 0.00624, params: {'min_samples_leaf': 40, 'min_samples_split': 1800},\n",
       "  mean: 0.83943, std: 0.00648, params: {'min_samples_leaf': 40, 'min_samples_split': 2000},\n",
       "  mean: 0.83955, std: 0.00626, params: {'min_samples_leaf': 40, 'min_samples_split': 2200},\n",
       "  mean: 0.83916, std: 0.00602, params: {'min_samples_leaf': 40, 'min_samples_split': 2400},\n",
       "  mean: 0.83918, std: 0.00613, params: {'min_samples_leaf': 50, 'min_samples_split': 1000},\n",
       "  mean: 0.83938, std: 0.00644, params: {'min_samples_leaf': 50, 'min_samples_split': 1200},\n",
       "  mean: 0.83940, std: 0.00655, params: {'min_samples_leaf': 50, 'min_samples_split': 1400},\n",
       "  mean: 0.83973, std: 0.00608, params: {'min_samples_leaf': 50, 'min_samples_split': 1600},\n",
       "  mean: 0.83929, std: 0.00610, params: {'min_samples_leaf': 50, 'min_samples_split': 1800},\n",
       "  mean: 0.83950, std: 0.00646, params: {'min_samples_leaf': 50, 'min_samples_split': 2000},\n",
       "  mean: 0.83948, std: 0.00613, params: {'min_samples_leaf': 50, 'min_samples_split': 2200},\n",
       "  mean: 0.83896, std: 0.00611, params: {'min_samples_leaf': 50, 'min_samples_split': 2400},\n",
       "  mean: 0.83966, std: 0.00637, params: {'min_samples_leaf': 60, 'min_samples_split': 1000},\n",
       "  mean: 0.83950, std: 0.00666, params: {'min_samples_leaf': 60, 'min_samples_split': 1200},\n",
       "  mean: 0.83956, std: 0.00596, params: {'min_samples_leaf': 60, 'min_samples_split': 1400},\n",
       "  mean: 0.83988, std: 0.00615, params: {'min_samples_leaf': 60, 'min_samples_split': 1600},\n",
       "  mean: 0.83923, std: 0.00619, params: {'min_samples_leaf': 60, 'min_samples_split': 1800},\n",
       "  mean: 0.83957, std: 0.00653, params: {'min_samples_leaf': 60, 'min_samples_split': 2000},\n",
       "  mean: 0.83968, std: 0.00641, params: {'min_samples_leaf': 60, 'min_samples_split': 2200},\n",
       "  mean: 0.83934, std: 0.00632, params: {'min_samples_leaf': 60, 'min_samples_split': 2400},\n",
       "  mean: 0.83950, std: 0.00599, params: {'min_samples_leaf': 70, 'min_samples_split': 1000},\n",
       "  mean: 0.83963, std: 0.00623, params: {'min_samples_leaf': 70, 'min_samples_split': 1200},\n",
       "  mean: 0.83987, std: 0.00621, params: {'min_samples_leaf': 70, 'min_samples_split': 1400},\n",
       "  mean: 0.83945, std: 0.00600, params: {'min_samples_leaf': 70, 'min_samples_split': 1600},\n",
       "  mean: 0.83989, std: 0.00634, params: {'min_samples_leaf': 70, 'min_samples_split': 1800},\n",
       "  mean: 0.83975, std: 0.00618, params: {'min_samples_leaf': 70, 'min_samples_split': 2000},\n",
       "  mean: 0.83953, std: 0.00608, params: {'min_samples_leaf': 70, 'min_samples_split': 2200},\n",
       "  mean: 0.83914, std: 0.00618, params: {'min_samples_leaf': 70, 'min_samples_split': 2400},\n",
       "  mean: 0.83971, std: 0.00638, params: {'min_samples_leaf': 80, 'min_samples_split': 1000},\n",
       "  mean: 0.83970, std: 0.00611, params: {'min_samples_leaf': 80, 'min_samples_split': 1200},\n",
       "  mean: 0.83943, std: 0.00619, params: {'min_samples_leaf': 80, 'min_samples_split': 1400},\n",
       "  mean: 0.83948, std: 0.00587, params: {'min_samples_leaf': 80, 'min_samples_split': 1600},\n",
       "  mean: 0.83979, std: 0.00586, params: {'min_samples_leaf': 80, 'min_samples_split': 1800},\n",
       "  mean: 0.83966, std: 0.00620, params: {'min_samples_leaf': 80, 'min_samples_split': 2000},\n",
       "  mean: 0.83960, std: 0.00633, params: {'min_samples_leaf': 80, 'min_samples_split': 2200},\n",
       "  mean: 0.83919, std: 0.00619, params: {'min_samples_leaf': 80, 'min_samples_split': 2400}],\n",
       " {'min_samples_leaf': 30, 'min_samples_split': 2000},\n",
       " 0.8400345451193825)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_split':[1000,1200,1400,1600,1800,2000,2200,2400], 'min_samples_leaf':[30,40,50,60,70,80]}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9,max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576602299509131"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.score(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_feature 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83821, std: 0.00614, params: {'max_features': 7},\n",
       "  mean: 0.83789, std: 0.00609, params: {'max_features': 9},\n",
       "  mean: 0.83771, std: 0.00626, params: {'max_features': 11},\n",
       "  mean: 0.83756, std: 0.00636, params: {'max_features': 13},\n",
       "  mean: 0.83849, std: 0.00635, params: {'max_features': 15},\n",
       "  mean: 0.83811, std: 0.00605, params: {'max_features': 17},\n",
       "  mean: 0.83837, std: 0.00645, params: {'max_features': 19},\n",
       "  mean: 0.83793, std: 0.00591, params: {'max_features': 21},\n",
       "  mean: 0.83798, std: 0.00567, params: {'max_features': 23},\n",
       "  mean: 0.83783, std: 0.00657, params: {'max_features': 25}],\n",
       " {'max_features': 15},\n",
       " 0.838487595152239)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':[7,9,11,13,15,17,19,21,23,25]}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.2, n_estimators=80,max_depth=7, min_samples_split=2000, min_samples_leaf=30, subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8670275420228308"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.score(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelfit(gsearch4, train, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subsample=.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83869, std: 0.00584, params: {'subsample': 0.5},\n",
       "  mean: 0.83878, std: 0.00564, params: {'subsample': 0.6},\n",
       "  mean: 0.83956, std: 0.00604, params: {'subsample': 0.7},\n",
       "  mean: 0.83954, std: 0.00560, params: {'subsample': 0.75},\n",
       "  mean: 0.83965, std: 0.00627, params: {'subsample': 0.8},\n",
       "  mean: 0.83925, std: 0.00575, params: {'subsample': 0.85},\n",
       "  mean: 0.83925, std: 0.00599, params: {'subsample': 0.9}],\n",
       " {'subsample': 0.8},\n",
       " 0.8396505447068365)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {'subsample':[0.5,0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.15, n_estimators=80,max_depth=5,min_samples_split=1200, min_samples_leaf=70, subsample=0.8, random_state=10,max_features=13),\n",
    "param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(train[predictors],train[target])\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n=200 leaning rate .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8409249783295585"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.1, n_estimators=200,max_depth=7, min_samples_split=2000,min_samples_leaf=30, subsample=0.8, random_state=10, max_features=15)\n",
    "# modelfit(gbm_tuned_1, train, predictors)\n",
    "gbm_tuned_1.fit(train[predictors],train[target])\n",
    "gbm_tuned_1.score(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n=1500 learning rate =.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8375136314067612"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "gbm_tuned_2 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=1500,max_depth=7, min_samples_split=2000,min_samples_leaf=30, subsample=0.8, random_state=10, max_features=15)\n",
    "# modelfit(gbm_tuned_1, train, predictors)\n",
    "gbm_tuned_2.fit(train[predictors],train[target])\n",
    "gbm_tuned_2.score(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n=2000 , learning rate .005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8375136314067612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "gbm_tuned_3 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=1500,max_depth=7, min_samples_split=2000,min_samples_leaf=30, subsample=0.8, random_state=10, max_features=15)\n",
    "# modelfit(gbm_tuned_1, train, predictors)\n",
    "gbm_tuned_3.fit(train[predictors],train[target])\n",
    "gbm_tuned_3.score(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "gbm_tuned_4 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=1500,max_depth=7, min_samples_split=2000,min_samples_leaf=30, subsample=0.8, random_state=10, max_features=15)\n",
    "# modelfit(gbm_tuned_1, train, predictors)\n",
    "gbm_tuned_4.fit(train[predictors],train[target])\n",
    "gbm_tuned_4.score(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 (25000, 43) gbm \n"
     ]
    }
   ],
   "source": [
    "lead_df=pd.read_csv('lead_board_manual_cleaned.csv',index_col='application_key')\n",
    "# lead_df.columns=colm[:-1]\n",
    "# lead_df=(lead_df-lead_df.mean(axis=0))/lead_df.std(axis=0)\n",
    "# lead_df=lead_df[imp_col[:-1]]\n",
    "# lead_df=Pca(lead_df)\n",
    "print(len(predictors),lead_df.shape, 'gbm ')\n",
    "\n",
    "\n",
    "lead_pred=gbm_tuned_3.predict(lead_df)\n",
    "proba=gbm_tuned_3.predict_proba(lead_df)\n",
    "lead_df['pridicted']=lead_pred\n",
    "lead_df['prob']=proba[:,0]\n",
    "lead_df=lead_df.sort_values(by=['prob'],ascending=False)\n",
    "result=lead_df['pridicted'].astype(int)\n",
    "result.to_csv('Datadevils_IITGuwahati_202.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch5 = GradientBoostingClassifier(n_estimators=80,learning_rate=0.1,max_depth=7,min_samples_split=2000, min_samples_leaf=30, subsample=0.75, random_state=10,max_features=15)\n",
    "gsearch5.fit(train[predictors],train[target])\n",
    "gsearch5.score(train[predictors],train[target])#grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8409\n",
      "AUC Score (Train): 0.872478\n",
      "CV Score : Mean - 0.8401147 | Std - 0.006200041 | Min - 0.8292882 | Max - 0.8464002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15b805d25f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelfit(gbm_tuned_1, train, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best_columns=[0,1,10,2,3,22,20,21,23,4,6,24,14,41,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution Manual Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 (25000, 43) gbm \n"
     ]
    }
   ],
   "source": [
    "lead_df=pd.read_csv('lead_board_manual_cleaned.csv',index_col='application_key')\n",
    "# lead_df.columns=colm[:-1]\n",
    "# lead_df=(lead_df-lead_df.mean(axis=0))/lead_df.std(axis=0)\n",
    "# lead_df=lead_df[imp_col[:-1]]\n",
    "# lead_df=Pca(lead_df)\n",
    "print(len(predictors),lead_df.shape, 'gbm ')\n",
    "\n",
    "\n",
    "lead_pred=gbm_tuned_2.predict(lead_df)\n",
    "proba=gbm_tuned_2.predict_proba(lead_df)\n",
    "lead_df['pridicted']=lead_pred\n",
    "lead_df['prob']=proba[:,0]\n",
    "lead_df=lead_df.sort_values(by=['prob'],ascending=False)\n",
    "result=lead_df['pridicted'].astype(int)\n",
    "result.to_csv('lead_1_training_mannual_label.csv')\n",
    "lead_df.to_csv('lead_data_manual_clean_with_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>pridicted</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577014</th>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3881.0</td>\n",
       "      <td>99100.0</td>\n",
       "      <td>21901.0</td>\n",
       "      <td>338223.0</td>\n",
       "      <td>199653.0</td>\n",
       "      <td>1876.5</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>83153.0</td>\n",
       "      <td>198200.0</td>\n",
       "      <td>551669.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.916</td>\n",
       "      <td>206.22</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>7756.0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>30386.0</td>\n",
       "      <td>8030.0</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>14.8333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.89863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588481</th>\n",
       "      <td>1931.0</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4955.0</td>\n",
       "      <td>18829.0</td>\n",
       "      <td>18829.0</td>\n",
       "      <td>269454.0</td>\n",
       "      <td>105060.0</td>\n",
       "      <td>1876.5</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>33776.0</td>\n",
       "      <td>198200.0</td>\n",
       "      <td>434443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.924</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2361.0</td>\n",
       "      <td>6996.0</td>\n",
       "      <td>6996.0</td>\n",
       "      <td>30386.0</td>\n",
       "      <td>10980.0</td>\n",
       "      <td>3437.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>23.3333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.88439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571176</th>\n",
       "      <td>1937.0</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>139662.0</td>\n",
       "      <td>24650.0</td>\n",
       "      <td>159420.0</td>\n",
       "      <td>236751.0</td>\n",
       "      <td>1876.5</td>\n",
       "      <td>2846.0</td>\n",
       "      <td>24717.0</td>\n",
       "      <td>77298.0</td>\n",
       "      <td>438226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.738</td>\n",
       "      <td>547.95</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>7178.0</td>\n",
       "      <td>7178.0</td>\n",
       "      <td>30386.0</td>\n",
       "      <td>10950.0</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>17.0833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.88458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584493</th>\n",
       "      <td>1881.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>24641.0</td>\n",
       "      <td>24641.0</td>\n",
       "      <td>229441.0</td>\n",
       "      <td>125990.0</td>\n",
       "      <td>1876.5</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>172487.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.572</td>\n",
       "      <td>2264.32</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2982.0</td>\n",
       "      <td>9733.0</td>\n",
       "      <td>9733.0</td>\n",
       "      <td>30386.0</td>\n",
       "      <td>9733.0</td>\n",
       "      <td>4471.0</td>\n",
       "      <td>1863.0</td>\n",
       "      <td>25.3333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.79656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585548</th>\n",
       "      <td>1915.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2478.0</td>\n",
       "      <td>29730.0</td>\n",
       "      <td>29730.0</td>\n",
       "      <td>125362.0</td>\n",
       "      <td>57901.0</td>\n",
       "      <td>1876.5</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>34107.0</td>\n",
       "      <td>49550.0</td>\n",
       "      <td>301867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.981</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>996.0</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>30386.0</td>\n",
       "      <td>5658.0</td>\n",
       "      <td>2859.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>1.4167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.98987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0       1    2    3    4       5         6        7  \\\n",
       "application_key                                                             \n",
       "577014           1939.0  0.0000  0.0  0.0  0.0  3881.0   99100.0  21901.0   \n",
       "588481           1931.0  0.0560  0.0  0.0  0.0  4955.0   18829.0  18829.0   \n",
       "571176           1937.0  0.0071  0.0  0.0  0.0  3270.0  139662.0  24650.0   \n",
       "584493           1881.0  0.0000  0.0  0.0  0.0  1015.0   24641.0  24641.0   \n",
       "585548           1915.0  0.0000  0.0  0.0  0.0  2478.0   29730.0  29730.0   \n",
       "\n",
       "                        8         9      10       11        12        13  \\\n",
       "application_key                                                            \n",
       "577014           338223.0  199653.0  1876.5   3149.0   83153.0  198200.0   \n",
       "588481           269454.0  105060.0  1876.5   3551.0   33776.0  198200.0   \n",
       "571176           159420.0  236751.0  1876.5   2846.0   24717.0   77298.0   \n",
       "584493           229441.0  125990.0  1876.5  15596.0  172487.0       0.0   \n",
       "585548           125362.0   57901.0  1876.5   2077.0   34107.0   49550.0   \n",
       "\n",
       "                       14   15   16   17   18   19      20       21      22  \\\n",
       "application_key                                                               \n",
       "577014           551669.0  0.0  0.0  0.0  0.0  0.0  12.916   206.22  3300.0   \n",
       "588481           434443.0  0.0  0.0  0.0  0.0  0.0  15.924     0.00     0.0   \n",
       "571176           438226.0  0.0  0.0  0.0  0.0  0.0   7.738   547.95  1000.0   \n",
       "584493           252016.0  0.0  0.0  0.0  0.0  0.0  14.572  2264.32  3300.0   \n",
       "585548           301867.0  0.0  0.0  0.0  0.0  0.0   9.981     0.00  3300.0   \n",
       "\n",
       "                    23      24      25      26       27       28      29  \\\n",
       "application_key                                                            \n",
       "577014            3.85  1236.0  7756.0  3042.0  30386.0   8030.0  3620.0   \n",
       "588481            3.60  2361.0  6996.0  6996.0  30386.0  10980.0  3437.0   \n",
       "571176            3.11  2105.0  7178.0  7178.0  30386.0  10950.0  3620.0   \n",
       "584493           11.26  2982.0  9733.0  9733.0  30386.0   9733.0  4471.0   \n",
       "585548            6.26   996.0  2738.0  2738.0  30386.0   5658.0  2859.0   \n",
       "\n",
       "                     30       31   32    33   34   35   36    37       38  \\\n",
       "application_key                                                             \n",
       "577014           1138.0  14.8333  4.0  22.0  8.0  0.0  0.0  15.0  0.89863   \n",
       "588481           2483.0  23.3333  3.0  22.0  7.0  0.0  0.0  23.0  0.88439   \n",
       "571176           2006.0  17.0833  9.0  21.0  4.0  0.0  0.0  19.0  0.88458   \n",
       "584493           1863.0  25.3333  6.0  13.0  4.0  0.0  0.0  21.0  0.79656   \n",
       "585548            819.0   1.4167  3.0  21.0  2.0  0.0  0.0   7.0  0.98987   \n",
       "\n",
       "                  39   40      41   42  pridicted      prob  \n",
       "application_key                                              \n",
       "577014           1.0  0.0   0.000  0.0        0.0  0.992949  \n",
       "588481           1.0  0.0  81.294  0.0        0.0  0.992891  \n",
       "571176           1.0  0.0   0.000  0.0        0.0  0.992678  \n",
       "584493           1.0  0.0   0.000  0.0        0.0  0.992582  \n",
       "585548           1.0  0.0   0.000  0.0        0.0  0.992578  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
